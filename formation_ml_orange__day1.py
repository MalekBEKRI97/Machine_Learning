# -*- coding: utf-8 -*-
"""formation_ML_Orange-_Day1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hGqUvkqxVs0sbJIM0GMYPlmrd8OytUdn

## Part 1: Google Colab
"""

# Colab yista3mel seulement Python 3
number = 103
number += 1
print(number)

# Najem nista3mel les fonctions linux, lezim juste nzid 9balhom symbole !
# fama des commandes simples tist7a9ech fehom symbol, mais ki twali compliqué tist7a9
# Puisque Colab dima ya3mlou fi des updates, maybe ma3ach nist7a9ou

# fama code snippets 3al isar tnajem tjib minhom codet 7adhra
# fama files and folders tnajem thot fehom les fichiers w tuploadi etc.

# kol ma ta3mel connecté, il session hedhi ma idoum ken 12 se3a w ba3dha t9oss
# t9oss ma3netha lezim t3awed ta3mel connecté w tikhsir les fichiers te3ik du coup lezim t3awid tuploadi

# t9oss zeda ki tab9a se3a maghir ma t7arik chay (idle)
# code js t7otou fil console ya3mel simulation click 
# https://www.codegrepper.com/code-examples/go/prevent+colab+from+disconnecting

# bch nwali nikhdim 3al GPU, nimchi Runtime -> Change Runtime Type -> GPU
# bch narja3 CPU, Runtime -> Change Runtime Type -> None
# najmou na3mlou !nivida-smi bch nchoufou ken 3ana GPU wale
!nvidia-smi
# ken 3Malt hal commande w tjik erreur "failed to" rak en mode cpu, badel gpu

"""## Part 2: Data Science"""

import pandas

# read_csv ta9ra fichier csv cheya7 w trodou fi haja ismha dataframe
# li hiya variable feha barcha des méthodes 7adhra ise3douna

# najem soit na3ti lien lil fichier mil pc te3i wala lien min fichier mil web
dataset = pandas.read_csv('pokedex.csv')
dataset = pandas.read_csv("https://raw.githubusercontent.com/elyesmanai/Datasets-for-ML-trainings/main/pokedex_(Update_05.20).csv")

# pandas 3andha barcha anwe3 ta3 read, selon type de fichier te3ik

# n7ib na3ref 9adeh 3andi min lignes w colonnes
dataset.shape # ta3tini (lignes, colonnes)

# dataset.columns ta3tina esemi les colonnes lkol
dataset.columns

# dataset.drop tfasakh des lignes wala des colonnes.
# lezim awil parametre ikoun liste [] ta3 les colonnes, w ta3mel axis=1 bch ya3rfou anou colonnes
# mahouch bch isir changement à moins que n9olou inplace=True wala na3mel dataset = dataset.drop()
dataset.drop(['Unnamed: 0', 'pokedex_number', 'german_name', 'japanese_name'], axis=1, inplace=True)

"""**Exercice 1:**

- refaire le travail sur la meme dataset
- refaire le travail sur une nouvelle dataset que vous choisirez
"""

# bch nra awil 5 lignes fil data
dataset.head()
# bch nra ekhir 5 lignes
dataset.tail()
# bch nra ligne au hasard
dataset.sample()

# info() ta3tini des informations mil bara 3al data
# mil bara no9sdou nbr lignes, nbr colonnes, type
# 3ala kol colonne 9adeh min valeure nulle et type de colonne
# aussi 9adeh min type en total w 9adeh tekil en mémoire
dataset.info()

# describe ta3tini des information mil dekhil il data
# 3ala kol colonne, 9adeh min valeure, moyenne, std, valeur min, valeur max et distribution
dataset.describe()

# najmou nzidou include="object" li describe bch ntolou 3al colonnes li fehom texte
dataset.describe(include="object")

data.dtypes #ta3tik les types bark

# isna() ta3tini ken valeur nulle ou pas.
# isna().sum() ta3tini 3ala kol colonne 9adeh min valeur nulle
# isna().sum().sum() ta3tini fil dataset lkolha 9adeh min valeur nulle
dataset.isna().sum()

# Merci Meriem pour la correction

# NOTE: rodou belkom
# fama marat les valeurs nulles maktoubin NaN en format texe, du coup ghalet fehom
# najmou n7iloha b tari9 simple mais feature preprocessing mahouch fil object te3na tawa.

# najem naccedi les valeures ta3 colonne en faisant dataframe[nom_colonne]
dataset['generation']

# najem na3ref les valeurs uniques fi une colonne avec unique()
vals = dataset['generation'].unique()
# najem na3ref 9adeh min valeur unique que nunique()
nuni = dataset['generation'].nunique()
print(vals, nuni)

# tabdil nom des colonnes
dataset.rename(columns={'generation':'gen'}, inplace=True)
dataset.columns

# tasna3 colonne jdida ta3mel dataset[ism_jdid] = valeur, valeur tnajem tkoun fonction
dataset["semi_densité"] = dataset['weight_kg'] / dataset['height_m']
dataset['semi_densité']

# filtering li howa ya3ni raja3li il jme3a ili 3andhom haka wala haka
legends = dataset[ dataset['status'] == "Legendary" ]
fake = dataset[ dataset['gen'] != 1 ]
jbal = dataset[ dataset['height_m'] > 80 ]

# filtering bou barcha conditions juste nzidou & (et) wala | (ou) mabinhom 
# w nhotou kol condition fi prenthèse
dataset[ (dataset['status'] == "Legendary") & (dataset['gen'] != 1) & (dataset['gen'] != 1) ]

dataset['height_m'].plot()

dataset[dataset['height_m'] < 100 ]['height_m'].plot()

dataset.plot(x="height_m", y="weight_kg", style="o")

dataset.to_csv('new_pokedex.csv',index=False)

pandas.read_csv('new_pokedex.csv')